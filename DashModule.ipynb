{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd70d3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHYY\n",
      "   7.1\n",
      "   7.2\n",
      "   7.3\n",
      "   7.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwalal\\AppData\\Local\\Temp\\ipykernel_30172\\1893965733.py:1027: FutureWarning: Setting the `book` attribute is not part of the public API, usage can give unexpected or corrupted results and will be removed in a future version\n",
      "  writer.book = book\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def forecastImport(con):\n",
    "    fc = pd.read_excel(\"UPDATE.xlsx\",sheet_name=\"FORECAST\")\n",
    "    fc['Item Number'] = fc['Item Number'].astype(str)\n",
    "    fc = pd.merge(fc, con[['Item Number',\"Conversion Factor\"]], on='Item Number', how='left')\n",
    "    fc['Conversion Factor'] = fc['Conversion Factor'].fillna(1)\n",
    "    fc.iloc[:,2:-1]=fc.iloc[:,2:-1].multiply(fc.iloc[:,-1], axis=0)\n",
    "    fc =  fc.drop(\"Conversion Factor\", axis=1)\n",
    "    return fc\n",
    "\n",
    "def oldForecastImport(con):\n",
    "    ofc = pd.read_excel(\"UPDATE.xlsx\",sheet_name=\"PASTFORECAST\")\n",
    "    ofc['Item Number'] = ofc['Item Number'].astype(str)\n",
    "    ofc = pd.merge(ofc, con[['Item Number',\"Conversion Factor\"]], on='Item Number', how='left')\n",
    "    ofc['Conversion Factor'] = ofc['Conversion Factor'].fillna(1)\n",
    "    ofc.iloc[:,2:-1]=ofc.iloc[:,2:-1].multiply(ofc.iloc[:,-1], axis=0)\n",
    "    ofc =  ofc.drop(\"Conversion Factor\", axis=1)\n",
    "    return ofc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forsImport(con):\n",
    "    fors = pd.read_excel(\"UPDATE.xlsx\", sheet_name=\"FORS\")\n",
    "    fors =  fors.rename(columns={\"2nd Item Number\":\"Item Number\"})\n",
    "    fors['Item Number'] = fors['Item Number'].astype(str)\n",
    "    fors = fors.fillna(0)\n",
    "    fors = pd.merge(fors, con[['Item Number',\"Conversion Factor\"]], on='Item Number', how='left')\n",
    "    fors['Conversion Factor'] = fors['Conversion Factor'].fillna(1)\n",
    "    fors['Safety Stk 164'] = fors['Safety Stk 164'].astype(int) * fors['Conversion Factor']\n",
    "    fors['Safety Stk 166'] = fors['Safety Stk 166'].astype(int) * fors['Conversion Factor']\n",
    "    fors['Safety Stk 168'] = fors['Safety Stk 168'].astype(int) * fors['Conversion Factor']\n",
    "    fors =  fors.drop(\"Conversion Factor\", axis=1)\n",
    "    return fors\n",
    "    \n",
    "def orderFileImport():\n",
    "    orders = pd.read_excel(\"FILE.xlsx\", sheet_name=\"OPEN_ORDERS\")\n",
    "    orders = pd.DataFrame(orders)\n",
    "    orders = orders.rename(columns={\"Item\\nNumber\":\"Item Number\"})\n",
    "    orders['Item Number'] = orders['Item Number'].astype(str)\n",
    "    orders['Sales Reporting Code 03'] = orders['Sales Reporting Code 03'].astype(int)\n",
    "    orders['KEY2'] = orders['Order\\nNumber'].astype(str)+orders['Item Number'].astype(str)\n",
    "    return orders\n",
    "\n",
    "def accountFileImport():\n",
    "    acc = pd.read_excel(\"FILE.xlsx\",sheet_name=\"ACCOUNT\")\n",
    "    acc = acc.fillna(0)\n",
    "    acc['SOLDTO_ACC'] = acc['SOLDTO_ACC'].astype(int)\n",
    "    acc['SalesCode'] = acc['SalesCode'].astype(int)\n",
    "    acc['RBU'] = acc['RBU'].astype(int)\n",
    "    acc['KEY1'] = acc['RBU'].astype(str)+\"_\"+acc['SalesCode'].astype(str)+\"_\"+acc['SOLDTO_ACC'].astype(str)\n",
    "    acc = acc.drop_duplicates(subset='KEY1',keep='last')\n",
    "    acc = acc[['GROUP','DIVISION','RBU','SalesCode','SOLDTO_ACC','SOLDTO_NAME','Customer',\"KEY1\"]]\n",
    "    return acc\n",
    "\n",
    "def budgetFileImport(date):\n",
    "    budget = pd.read_excel(\"UPDATE.xlsx\", sheet_name = \"BUDGET\")\n",
    "    bud = budget[['RBU','Address Number','Item Number - Free Format','Sales Category Code 3',date['Month'].iloc[0]]]\n",
    "    bud = bud.rename(columns = {\"Item Number - Free Format\":\"Item Number\",date['Month'].iloc[0]:\"Budget\"})\n",
    "    bud[['SOLDTO_ACC', 'SOLDTO_NAME']] = bud['Address Number'].str.split(pat='-', n=1, expand=True)\n",
    "    bud['SOLDTO_ACC'] = bud['SOLDTO_ACC'].str.strip()\n",
    "    bud['SOLDTO_ACC'] = bud['SOLDTO_ACC'].str.strip()\n",
    "    bud['Sales Category Code 3'] = bud['Sales Category Code 3'].replace(' ', np.nan)\n",
    "    bud['Sales Category Code 3'] = bud['Sales Category Code 3'].astype(float).astype(pd.Int64Dtype())\n",
    "    bud['KEY1'] = bud['RBU'].astype(str)+\"_\"+bud['Sales Category Code 3'].astype(str)+\"_\"+bud['SOLDTO_ACC'].astype(str)\n",
    "    bud['Item Number'] = bud['Item Number'].astype(str)\n",
    "    budx = bud\n",
    "    bud = bud.groupby(['KEY1'])['Budget'].sum()\n",
    "    bud = pd.DataFrame(bud)\n",
    "    bud.reset_index(inplace=True)\n",
    "    \n",
    "    return bud, budx\n",
    "\n",
    "def mtdFileImport(con):\n",
    "    mtd = pd.read_excel(\"UPDATE.xlsx\", sheet_name=\"MTD\")\n",
    "    \n",
    "    mtd = mtd.dropna()\n",
    "    mtd[['SOLDTO_ACC', 'SOLDTO_NAME']] = mtd['Sold\\nTo'].str.split(pat='-', n=1, expand=True)\n",
    "    mtd['SOLDTO_ACC'] = mtd['SOLDTO_ACC'].str.strip()\n",
    "    mtd['SOLDTO_NAME'] = mtd['SOLDTO_NAME'].str.strip()\n",
    "\n",
    "    mtd[['RBU', 'RBU_NAME']] = mtd['BU\\nHeader'].str.split(pat='-', n=1, expand=True)\n",
    "    mtd['RBU'] = mtd['RBU'].str.strip()\n",
    "    mtd['RBU_NAME'] = mtd['RBU_NAME'].str.strip()\n",
    "\n",
    "    mtd[['SalesCode', 'Code_name']] = mtd['Sales Cat 03'].str.split(pat='-', n=1, expand=True)\n",
    "    mtd['SalesCode'] = mtd['SalesCode'].str.strip()\n",
    "    mtd['Code_name'] = mtd['Code_name'].str.strip()\n",
    "\n",
    "    mtd['RBU'] = mtd['RBU'].astype(int)\n",
    "    mtd['SalesCode'] = mtd['SalesCode'].astype(int)\n",
    "    mtd['Branch/\\nPlant'] = mtd['Branch/\\nPlant'].astype(int)\n",
    "    mtd['SOLDTO_ACC'] = mtd['SOLDTO_ACC'].astype(int)\n",
    "\n",
    "    mtd = mtd.rename(columns={\"Item\\nNumber\":\"Item Number\",\"Qty\\nShipped\\nto Date\":\"QtyShipped\"})\n",
    "    mtd['Item Number'] = mtd['Item Number'].astype(str)\n",
    "    mtd = pd.merge(mtd, con[[\"Item Number\",\"Conversion Factor\"]], on=\"Item Number\", how='left')\n",
    "    mtd['Conversion Factor'] = mtd['Conversion Factor'].fillna(1)\n",
    "    mtd['QtyShipped'] = mtd['Conversion Factor'].astype(int) * mtd['QtyShipped'].astype(int)\n",
    "\n",
    "    mtd['KEY1'] = mtd['RBU'].astype(str)+\"_\"+mtd['SalesCode'].astype(str)+\"_\"+mtd['SOLDTO_ACC'].astype(str)\n",
    "    \n",
    "    mtd['KEY2'] = mtd['Order\\nNumber'].astype(str)+mtd['Document\\nNumber'].astype(str)+mtd['Line\\nNumber'].astype(str)\n",
    "    \n",
    "    mtd = mtd.drop_duplicates(subset='KEY2', keep='last')\n",
    "    \n",
    "    mtd = mtd[(mtd['SalesCode']!=250)|(mtd['SalesCode']!=500)|(mtd['SalesCode']!=110)]\n",
    "    \n",
    "    return mtd\n",
    "\n",
    "def otherFileImport():\n",
    "    date = pd.read_excel(\"File.xlsx\",sheet_name=\"ORDERDATE\")\n",
    "    con = pd.read_excel(\"FILE.xlsx\",sheet_name=\"CONVERSION\")\n",
    "    return date, con\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "date, con = otherFileImport()\n",
    "\n",
    "orders = orderFileImport()\n",
    "\n",
    "acc = accountFileImport()\n",
    "\n",
    "mtd = mtdFileImport(con)\n",
    "bud, budx = budgetFileImport(date)\n",
    "fors = forsImport(con)\n",
    "\n",
    "fc = forecastImport(con)\n",
    "ofc = oldForecastImport(con)\n",
    "\n",
    "def pFCExtract(con,ofc):\n",
    "\n",
    "    pfc = ofc.groupby('Item Number').apply(lambda x: x.iloc[:, 2:5].sum())\n",
    "    pfc.reset_index(inplace=True)\n",
    "    return pfc\n",
    "\n",
    "pfc = pFCExtract(con,ofc)\n",
    "\n",
    "def lastFC(ofc,fors):\n",
    "    lfc = pd.merge(ofc,fors[['Item Number','Sls Cd3']], on='Item Number', how='left')\n",
    "    lfc = lfc.rename(columns={\"Sls Cd3\":\"SalesCode\"})\n",
    "    lfc['SalesCode'] = lfc['SalesCode'].replace(' ', np.nan)\n",
    "    lfc['SalesCode'] = lfc['SalesCode'].astype(float).astype(pd.Int64Dtype())\n",
    "    lfc['KEY3'] = lfc['RBU'].astype(str)+\"_\"+lfc['SalesCode'].astype(str)+\"_\"+lfc['Item Number'].astype(str)\n",
    "    \n",
    "    return lfc\n",
    "lfc = lastFC(ofc,fors)\n",
    "   \n",
    "    \n",
    "def concatProcess_sales(mtd,acc,bud):\n",
    "    print(\"WHYY\")\n",
    "    custSales = mtd.groupby(['KEY1'])['QtyShipped'].sum()\n",
    "    custSales = pd.DataFrame(custSales)\n",
    "    custSales.reset_index(inplace=True)\n",
    "    print(\"   7.1\")\n",
    "    \n",
    "    acc = pd.merge(acc, bud, on=\"KEY1\",how='left')\n",
    "    UnRegisteredBudget = bud[~bud['KEY1'].isin(acc['KEY1'])]\n",
    "    print(\"   7.2\")\n",
    "    \n",
    "    acc = pd.merge(acc,custSales, on=\"KEY1\", how='left')\n",
    "    acc['QtyShipped'] = acc['QtyShipped'].fillna(0)\n",
    "    print(\"   7.3\")\n",
    "    \n",
    "    UnRegistered = custSales[~custSales['KEY1'].isin(acc['KEY1'])]\n",
    "    UnRegistered = pd.merge(UnRegistered,mtd[['KEY1','Ship\\nTo','SOLDTO_ACC', 'SOLDTO_NAME', 'RBU', 'RBU_NAME', 'SalesCode']], \n",
    "                       on=\"KEY1\", how=\"left\")\n",
    "    print(\"   7.4\")\n",
    "    \n",
    "    acc = acc.drop_duplicates(subset='KEY1', keep=\"last\")\n",
    "    \n",
    "    return acc, UnRegistered, UnRegisteredBudget\n",
    "\n",
    "def concatProcess_orders(acc,orders,con):\n",
    "    orders = pd.merge(orders,con[[\"Item Number\",\"Conversion Factor\"]], on=\"Item Number\", how='left')\n",
    "    orders = orders.drop_duplicates(subset=\"KEY2\", keep='last')\n",
    "    orders['Conversion Factor'] = orders['Conversion Factor'].fillna(1)\n",
    "    \n",
    "    orders['TotalOpenOrders'] = orders['Qty\\nOrder/\\nTransaction'].astype(int)*orders['Conversion Factor'].astype(int)\n",
    "    orders['TotalBackOrders'] = orders['Qty\\nBackorder/\\nHeld'].astype(int)*orders['Conversion Factor'].astype(int)\n",
    "    \n",
    "    def pastDue_Orders(row):\n",
    "        if row['Requested\\nDate'] < date['Beg_Month'].iloc[0]:\n",
    "            return row['TotalOpenOrders']\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def currDue_Orders(row):\n",
    "        if row['Requested\\nDate'] >= date['Beg_Month'].iloc[0] and row['Requested\\nDate'] <= date['End_Month'].iloc[0]:\n",
    "            return row['TotalOpenOrders']\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def postDue_Orders(row):\n",
    "        if row['Requested\\nDate'] > date['End_Month'].iloc[0]:\n",
    "            return row['TotalOpenOrders']\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Apply the custom_condition function to create a new column 'C' based on the condition\n",
    "    orders['PastDue_Orders'] = orders.apply(pastDue_Orders, axis=1)\n",
    "    orders['CurrDue_Orders'] = orders.apply(currDue_Orders, axis=1)\n",
    "    orders['PostDue_Orders'] = orders.apply(postDue_Orders, axis=1)\n",
    "    \n",
    "    def pastDue_bo(row):\n",
    "        if row['Requested\\nDate'] < date['Beg_Month'].iloc[0]:\n",
    "            return row['TotalBackOrders']\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def currDue_bo(row):\n",
    "        if row['Requested\\nDate'] >= date['Beg_Month'].iloc[0] and row['Requested\\nDate'] <= date['End_Month'].iloc[0]:\n",
    "            return row['TotalBackOrders']\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def postDue_bo(row):\n",
    "        if row['Requested\\nDate'] > date['End_Month'].iloc[0]:\n",
    "            return row['TotalBackOrders']\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Apply the custom_condition function to create a new column 'C' based on the condition\n",
    "    orders['PastDue_BO'] = orders.apply(pastDue_bo, axis=1)\n",
    "    orders['CurrDue_BO'] = orders.apply(currDue_bo, axis=1)\n",
    "    orders['PostDue_BO'] = orders.apply(postDue_bo, axis=1)\n",
    "\n",
    "    orders['KEY1'] = orders['BU\\nHeader'].astype(str)+\"_\"+orders['Sales Reporting Code 03'].astype(str)+\"_\"+orders['Sold\\nTo'].astype(str)\n",
    "    \n",
    "    grp = orders.groupby(['KEY1'])[['TotalOpenOrders','TotalBackOrders',\"PastDue_Orders\",\"CurrDue_Orders\",\"PostDue_Orders\",\n",
    "                               \"PastDue_BO\",\"CurrDue_BO\",\"PostDue_BO\"]].sum()\n",
    "    grp = pd.DataFrame(grp)\n",
    "    grp.reset_index(inplace=True)\n",
    "    acc = pd.merge(acc,grp[['KEY1','TotalOpenOrders',\"TotalBackOrders\",\n",
    "                           'PastDue_Orders','CurrDue_Orders','PostDue_Orders',\n",
    "                          \"PastDue_BO\",'CurrDue_BO','PostDue_BO']], on='KEY1',how='left')\n",
    "    \n",
    "    UnRegisteredOrders = orders[~orders['KEY1'].isin(acc['KEY1'])]\n",
    "    \n",
    "    acc = acc.drop_duplicates(subset='KEY1', keep=\"last\")\n",
    "    \n",
    "    return acc, UnRegisteredOrders, orders\n",
    "    \n",
    "\n",
    "\n",
    "acc, UnRegistered, UnRegisteredBudget = concatProcess_sales(mtd,acc,bud)\n",
    "\n",
    "acc, UnRegisteredOrders, orders = concatProcess_orders(acc,orders,con)\n",
    "\n",
    "\n",
    "def itemProcess(budx,mtd,orders,fc,acc,fors,pfc):\n",
    "    budx = budx.rename(columns={'Sales Category Code 3':\"SalesCode\"})\n",
    "    budx['KEY3'] = budx['RBU'].astype(str)+\"_\"+budx['SalesCode'].astype(str)+\"_\"+budx['Item Number'].astype(str)\n",
    "    budx = budx.groupby(['KEY3','RBU','SalesCode','Item Number'])['Budget'].sum()\n",
    "    budx = pd.DataFrame(budx)\n",
    "    budx.reset_index(inplace=True)\n",
    "    \n",
    "    mtd['KEY3'] = mtd['RBU'].astype(str)+\"_\"+mtd['SalesCode'].astype(str)+\"_\"+mtd['Item Number'].astype(str)\n",
    "    mtd = mtd[['KEY3','RBU',\"SalesCode\",\"Item Number\",\"QtyShipped\"]]\n",
    "    mtd = mtd.groupby(['KEY3','RBU','SalesCode','Item Number'])['QtyShipped'].sum()\n",
    "    mtd = pd.DataFrame(mtd)\n",
    "    mtd.reset_index(inplace=True)\n",
    "    \n",
    "    fc = pd.merge(fc,fors[['Item Number','Sls Cd3']],on='Item Number',how='left')\n",
    "    fc['Sls Cd3'] = fc['Sls Cd3'].replace(' ', np.nan)\n",
    "    fc['Sls Cd3'] = fc['Sls Cd3'].astype(float).astype(pd.Int64Dtype())\n",
    "    fc = fc.rename(columns={\"Sls Cd3\":\"SalesCode\"})\n",
    "    fc['KEY3'] = fc['RBU'].astype(str)+\"_\"+fc['SalesCode'].astype(str)+\"_\"+fc['Item Number'].astype(str)\n",
    "    fc = fc.groupby(['KEY3', 'RBU',\"SalesCode\", 'Item Number']).apply(lambda x: x.iloc[:, 2:5].sum())\n",
    "    fc.reset_index(inplace=True)\n",
    "    \n",
    "    test = pd.merge(budx,fc, on=['KEY3','RBU',\"SalesCode\",'Item Number'], how='outer')\n",
    "    test = test.fillna(0)\n",
    "    \n",
    "    test = pd.merge(test,mtd,on=['KEY3','RBU',\"SalesCode\",'Item Number'], how=\"outer\")\n",
    "    test = test.fillna(0)\n",
    "    \n",
    "    orders = orders.rename(columns={'Sales Reporting Code 03':\"SalesCode\"})\n",
    "    orders['SalesCode'] = orders['SalesCode'].replace(' ', np.nan)\n",
    "    orders['SalesCode'] = orders['SalesCode'].astype(float).astype(pd.Int64Dtype())\n",
    "    \n",
    "    ordersx = orders[['BU\\nHeader',\"SalesCode\",\"Item Number\",'TotalOpenOrders',\"TotalBackOrders\",\n",
    "                  'PastDue_Orders','CurrDue_Orders','PostDue_Orders',\n",
    "                  \"PastDue_BO\",'CurrDue_BO','PostDue_BO']]\n",
    "    ordersx = ordersx.rename(columns = {'BU\\nHeader':\"RBU\"})\n",
    "    ordersx['KEY3'] = ordersx['RBU'].astype(str)+\"_\"+ordersx['SalesCode'].astype(str)+\"_\"+ordersx['Item Number'].astype(str)\n",
    "    ordersx = ordersx.groupby(['KEY3', 'RBU',\"SalesCode\",'Item Number'])[['TotalOpenOrders', 'TotalBackOrders',\n",
    "                                                       'PastDue_Orders', 'CurrDue_Orders',\n",
    "                                                       'PostDue_Orders', 'PastDue_BO',\n",
    "                                                       'CurrDue_BO', 'PostDue_BO']].sum()\n",
    "    ordersx.reset_index(inplace=True)\n",
    "    \n",
    "    test = pd.merge(test,ordersx,on=['KEY3','RBU',\"SalesCode\",'Item Number'], how=\"outer\")\n",
    "    test = test.fillna(0)\n",
    "    test = test.drop_duplicates(subset='KEY3', keep='last')\n",
    "    \n",
    "    rbu = acc[['GROUP','DIVISION','RBU','SalesCode']]\n",
    "    rbu = rbu.drop_duplicates(subset=['GROUP','DIVISION','RBU','SalesCode'], keep='last')\n",
    "    rbu['KEY4'] = rbu['RBU'].astype(str)+\"_\"+rbu['SalesCode'].astype(str)\n",
    "    \n",
    "    #test = pd.merge(test, fors[['Item Number',\"Sls Cd3\"]], on=\"Item Number\", how='left')\n",
    "    ##test['Sls Cd3'] = test['Sls Cd3'].replace(' ', np.nan)\n",
    "    #test['Sls Cd3'] = test['Sls Cd3'].astype(float).astype(pd.Int64Dtype())\n",
    "    test['KEY4'] = test['RBU'].astype(str)+\"_\"+test['SalesCode'].astype(str)\n",
    "    \n",
    "    test = pd.merge(test,rbu[['KEY4','GROUP','DIVISION']], on='KEY4',how='left')\n",
    "    test = test.drop_duplicates(subset='KEY3', keep='last')\n",
    "    \n",
    "    return test\n",
    "\n",
    "test = itemProcess(budx,mtd,orders,fc,acc,fors,pfc)\n",
    "\n",
    "def wo_prep(con):\n",
    "    wo = pd.read_excel(\"UPDATE.xlsx\",sheet_name=\"WORKORDER\")\n",
    "    from datetime import datetime, date,timedelta\n",
    "    wo['[SCHEDULED DATE]'] = pd.to_datetime(wo['[SCHEDULED DATE]'], format='%d-%m-%Y')\n",
    "    wo['Year'] = wo['[SCHEDULED DATE]'].dt.year\n",
    "    wo['Year'] = wo['Year'].astype(int)\n",
    "    wo['Month'] = wo['[SCHEDULED DATE]'].dt.month\n",
    "    wo['Month'] = wo['Month'].astype(int)\n",
    "    wo['weekofyear'] = wo['[SCHEDULED DATE]'].dt.isocalendar().week\n",
    "    wo['weekofyear'] = wo['weekofyear'].astype(int)\n",
    "    wo['Today'] = date.today()\n",
    "    wo['TodayW'] = wo['Today'].apply(lambda x:x.isocalendar()[1])\n",
    "    wo['TodayY'] = pd.to_datetime(wo['Today'])\n",
    "    wo['TodayY'] =  wo['TodayY'].dt.year\n",
    "    \n",
    "    conn = con\n",
    "    conn = conn.rename(columns={\"Item Number\":\"ITEM NUMBER\"})\n",
    "    wo = pd.merge(wo,conn[['ITEM NUMBER',\"Conversion Factor\"]], on='ITEM NUMBER',how='left')\n",
    "    wo['Conversion Factor'] = wo['Conversion Factor'].fillna(1)\n",
    "    wo['[QTY OUTSTANDING]'] = wo['[QTY OUTSTANDING]'].astype(float)*wo['Conversion Factor'].astype(float)\n",
    "\n",
    "    conditions = [\n",
    "        (wo['Year'] < wo['TodayY']),\n",
    "        (wo['Year'] == wo['TodayY']) & (wo['weekofyear'] < wo['TodayW']),\n",
    "        (wo['Year'] == wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']),\n",
    "        (wo['Year'] == wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']+1),\n",
    "        (wo['Year'] == wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']+2),\n",
    "        (wo['Year'] == wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']+3),\n",
    "        (wo['Year'] == wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']+4),\n",
    "        (wo['Year'] == wo['TodayY']) & (wo['weekofyear'] > wo['TodayW']+4),\n",
    "        (wo['Year'] > wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']+1),\n",
    "        (wo['Year'] > wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']+2),\n",
    "        (wo['Year'] > wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']+3),\n",
    "        (wo['Year'] > wo['TodayY']) & (wo['weekofyear'] == wo['TodayW']+4),\n",
    "        (wo['Year'] > wo['TodayY']) & (wo['weekofyear'] > wo['TodayW']+4)]\n",
    "\n",
    "    values = ['ByPass', 'ByPass', 'Current', 'Curr+1','Curr+2','Curr+3','Curr+4','Curr+5','Curr+1','Curr+2','Curr+3','Curr+4','Curr+5']\n",
    "\n",
    "    \n",
    "    wo['WO_Status'] = np.select(conditions, values)\n",
    "\n",
    "    cols = ['ByPass', 'Current', 'Curr+1','Curr+2','Curr+3','Curr+4','Curr+5']\n",
    "\n",
    "    for i in range(7):\n",
    "\n",
    "        condition = [wo['WO_Status']== cols[i]]\n",
    "        val = [wo['[QTY OUTSTANDING]']]\n",
    "\n",
    "        wo[cols[i]] = np.select(condition,val)\n",
    "        \n",
    "    wo = wo.fillna(0)\n",
    "\n",
    "    wo.rename(columns = {\"ITEM NUMBER\":\"Item Number\"}, inplace = True)\n",
    "    wo['Item Number'] = wo['Item Number'].astype(str)\n",
    "    wo = wo[[\"Item Number\",'ByPass', 'Current','Curr+1','Curr+2','Curr+3','Curr+4','Curr+5']]\n",
    "    wo = wo.pivot_table(index = \"Item Number\", aggfunc= \"sum\")\n",
    "    wo = wo.reset_index()\n",
    "    column_order = [\"Item Number\", 'ByPass', 'Current', 'Curr+1', 'Curr+2', 'Curr+3', 'Curr+4', 'Curr+5']\n",
    "    wo = wo[column_order]\n",
    "    \n",
    "    \n",
    "    \n",
    "    current_date = datetime.now()\n",
    "    days_until_friday = (4 - current_date.weekday() + 7) % 7\n",
    "    fridays = []\n",
    "    for _ in range(8):\n",
    "        fridays.append(\"WO \" + (current_date + timedelta(days=days_until_friday)).strftime(\"%d-%b\"))\n",
    "        days_until_friday += 7\n",
    "    \n",
    "    wo = wo.rename(columns={\"Curr+1\":fridays[1],\"Curr+2\":fridays[2],\n",
    "                       \"Curr+3\":fridays[3],\"Curr+4\":fridays[5],\n",
    "                       \"Curr+5\":\"WO POSTDUE\",\"ByPass\":\"WO ByPass\",\n",
    "                           \"Current\":\"WO Current\"})\n",
    "    wo['Item Number'] = wo['Item Number'].astype(str)\n",
    "    return wo\n",
    "wo = wo_prep(con)\n",
    "\n",
    "\n",
    "def sohExtract(con):\n",
    "    soh = pd.read_excel(\"UPDATE.xlsx\", sheet_name=\"SOH\")\n",
    "    soh = soh.rename(columns={\"Branch/\\nPlant\":\"WHS\"})\n",
    "    soh['Item Number'] = soh['Item\\nNumber'].str.rsplit(' ',expand=True)[0]\n",
    "    soh = pd.merge(soh,con[[\"Item Number\",\"Conversion Factor\"]], on='Item Number',how='left')\n",
    "    soh['Conversion Factor'] = soh['Conversion Factor'].fillna(1)\n",
    "    soh['Commited'] = soh['Commited'].astype(float)*soh['Conversion Factor'].astype(float)\n",
    "    soh['Available'] = soh['Available'].astype(float)*soh['Conversion Factor'].astype(float)\n",
    "    \n",
    "    \n",
    "    whs = soh[(soh[\"WHS\"]==\"164\")|(soh[\"WHS\"]==\"166\")|(soh[\"WHS\"]==\"168\")]\n",
    "    def lessThan(row):\n",
    "        if row['Available'] < 0:\n",
    "            return \"LESS\"\n",
    "        else:\n",
    "            return \"NA\"\n",
    "    whs['LessThan'] = whs.apply(lessThan, axis=1)\n",
    "    whs = whs[whs['LessThan'] != 'LESS']\n",
    "    \n",
    "    el = ['164','166','168']\n",
    "    dfs = []\n",
    "    for i in el:\n",
    "        df = whs[whs['WHS']==i]\n",
    "        dfs.append(df)\n",
    "        \n",
    "    for i in range(len(dfs)):\n",
    "        def classify(row):\n",
    "            if row['Location'] == \"R\":\n",
    "                return \"Rec_{}\".format(el[i])\n",
    "            elif row['Location'] == 'Q' or row['Location'] == \"H\"  or row['Location'] == \"HS\":\n",
    "                return \"QA_{}\".format(el[i])\n",
    "            else:\n",
    "                return \"Avail_{}\".format(el[i])\n",
    "        dfs[i]['Class'] = dfs[i].apply(classify,axis=1)\n",
    "        \n",
    "    whsDF = pd.concat(dfs, ignore_index=True)\n",
    "    whsDF = whsDF.pivot_table(index=\"Item Number\", columns=\"Class\", values=\"Available\",aggfunc=np.sum).rename_axis(index=None, columns=None)\n",
    "    whsDF = whsDF.fillna(0)\n",
    "    whsDF.reset_index(inplace=True)\n",
    "    whsDF = whsDF.rename(columns={\"index\":\"Item Number\"})\n",
    "    \n",
    "    \n",
    "    sohb = soh[(soh[\"WHS\"]!=\"164\")&(soh[\"WHS\"]!=\"166\")&(soh[\"WHS\"]!=\"168\")]\n",
    "    sohb = sohb[~sohb['WHS'].str.startswith(\"Total\")]\n",
    "    \n",
    "    sohb['LessThan'] = sohb.apply(lessThan, axis=1)\n",
    "    sohb = sohb[sohb['LessThan'] != 'LESS']\n",
    "    sohb = sohb.pivot_table(index=\"Item Number\", columns=\"WHS\", values=\"Available\",aggfunc=np.sum).rename_axis(index=None, columns=None)\n",
    "    \n",
    "    sohb.reset_index(inplace=True)\n",
    "    sohb = sohb.rename(columns={\"index\":\"Item Number\"})\n",
    "    sohb = sohb.fillna(0)\n",
    "    \n",
    "    \n",
    "    return whsDF,sohb\n",
    "\n",
    "whsDF,sohb = sohExtract(con)\n",
    "\n",
    "\n",
    "\n",
    "def salesExtract(con):\n",
    "    sales = pd.read_excel(\"UPDATE.xlsx\", sheet_name=\"6MSALES\")\n",
    "    sales =  sales.drop(\"Sales Cat Code\", axis=1)\n",
    "    sales = pd.merge(sales, con[['Item Number',\"Conversion Factor\"]], on='Item Number', how='left')\n",
    "    sales['Conversion Factor'] = sales['Conversion Factor'].fillna(1)\n",
    "    sales.iloc[:,1:-1]=sales.iloc[:,1:-1].multiply(sales.iloc[:,-1], axis=0)\n",
    "    sales =  sales.drop(\"Conversion Factor\", axis=1)\n",
    "    sales['6mAvg'] = round(sales.iloc[:, -6:].mean(axis=1),)\n",
    "    return sales\n",
    "\n",
    "#sales = salesExtract(con)\n",
    "\n",
    "def rbuSales(con):\n",
    "    \n",
    "    allsales = pd.read_excel(\"UPDATE.xlsx\", sheet_name=\"RBUSALES\")\n",
    "    allsales['Item Number'] = allsales['Item Number'].astype(str)\n",
    "    allsales = pd.merge(allsales, con[['Item Number',\"Conversion Factor\"]], on='Item Number', how='left')\n",
    "    allsales['Conversion Factor'] = allsales['Conversion Factor'].fillna(1)\n",
    "    allsales.iloc[:,3:-1]=allsales.iloc[:,3:-1].multiply(allsales.iloc[:,-1], axis=0)\n",
    "    allsales =  allsales.drop(\"Conversion Factor\", axis=1)\n",
    "    allsales = allsales[(allsales['Warehouse']==164)|(allsales['Warehouse']==166)|(allsales['Warehouse']==168)]\n",
    "    \n",
    "    sales = allsales.groupby('Item Number').sum().iloc[:, -6:]\n",
    "    sales.reset_index(inplace=True)\n",
    "    sales['6mAvg'] = round(sales.iloc[:, -6:].mean(axis=1),)\n",
    "    \n",
    "    \n",
    "    col = list(allsales.columns[-6:])\n",
    "    tsales = allsales.groupby(['Warehouse','Item Number']).sum().iloc[:, -6:]\n",
    "    tsales.reset_index(inplace=True)\n",
    "    warehouse_164 = pd.DataFrame()\n",
    "    warehouse_166 = pd.DataFrame()\n",
    "    warehouse_168 = pd.DataFrame()\n",
    "\n",
    "    # Filter rows for each warehouse and copy the \"Item Number\" column\n",
    "    warehouse_164['Item Number'] = tsales[tsales['Warehouse'] == 164]['Item Number'].values\n",
    "    warehouse_166['Item Number'] = tsales[tsales['Warehouse'] == 166]['Item Number'].values\n",
    "    warehouse_168['Item Number'] = tsales[tsales['Warehouse'] == 168]['Item Number'].values\n",
    "\n",
    "    # Loop through the rows of the initial dataframe and populate the new dataframes\n",
    "    for month in col:\n",
    "        warehouse_164[f\"164_{month}\"] = tsales[tsales['Warehouse'] == 164][month].values\n",
    "        warehouse_166[f\"166_{month}\"] = tsales[tsales['Warehouse'] == 166][month].values\n",
    "        warehouse_168[f\"168_{month}\"] = tsales[tsales['Warehouse'] == 168][month].values\n",
    "\n",
    "\n",
    "    warehouse_164.reset_index(drop=True, inplace=True)\n",
    "    warehouse_166.reset_index(drop=True, inplace=True)\n",
    "    warehouse_168.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return allsales,sales, warehouse_164,warehouse_166,warehouse_168\n",
    "\n",
    "allsales,sales, warehouse_164,warehouse_166,warehouse_168 = rbuSales(con)\n",
    "\n",
    "\n",
    "def previousBO(con,fors):\n",
    "    pbo = pd.read_excel(\"UPDATE.xlsx\",sheet_name=\"PBO\")\n",
    "    pbo['Item Number'] = pbo['Item Number'].astype(str)\n",
    "    pbo = pd.merge(pbo, con[['Item Number',\"Conversion Factor\"]], on='Item Number', how='left')\n",
    "    pbo['Conversion Factor'] = pbo['Conversion Factor'].fillna(1)\n",
    "    pbo.iloc[:,4:-1]=pbo.iloc[:,4:-1].multiply(pbo.iloc[:,-1], axis=0)\n",
    "    pbo =  pbo.drop(\"Conversion Factor\", axis=1)\n",
    "    \n",
    "    pItemBO = pbo.groupby('Item Number')[pbo.columns[4:]].sum()\n",
    "    pItemBO.reset_index(inplace=True)\n",
    "    \n",
    "    pwItemBO = pbo.groupby([\"Warehouse\",'Item Number'])[pbo.columns[4:]].sum()\n",
    "    pwItemBO.reset_index(inplace=True)\n",
    "    pwItemBO['Warehouse'] = pwItemBO['Warehouse'].astype(int)\n",
    "    col = pwItemBO.columns[-3:]\n",
    "    \n",
    "    warehouse_164y = pd.DataFrame()\n",
    "    warehouse_166y = pd.DataFrame()\n",
    "    warehouse_168y = pd.DataFrame()\n",
    "\n",
    "    # Filter rows for each warehouse and copy the \"Item Number\" column\n",
    "    warehouse_164y['Item Number'] = pwItemBO[pwItemBO['Warehouse'] == 164]['Item Number'].values\n",
    "    warehouse_166y['Item Number'] = pwItemBO[pwItemBO['Warehouse'] == 166]['Item Number'].values\n",
    "    warehouse_168y['Item Number'] = pwItemBO[pwItemBO['Warehouse'] == 168]['Item Number'].values\n",
    "\n",
    "    # Loop through the rows of the initial dataframe and populate the new dataframes\n",
    "    for month in col:\n",
    "        warehouse_164y[f\"164_{month}\"] = pwItemBO[pwItemBO['Warehouse'] == 164][month].values\n",
    "        warehouse_166y[f\"166_{month}\"] = pwItemBO[pwItemBO['Warehouse'] == 166][month].values\n",
    "        warehouse_168y[f\"168_{month}\"] = pwItemBO[pwItemBO['Warehouse'] == 168][month].values\n",
    "\n",
    "\n",
    "    warehouse_164y.reset_index(drop=True, inplace=True)\n",
    "    warehouse_166y.reset_index(drop=True, inplace=True)\n",
    "    warehouse_168y.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    pRItemBO = pd.merge(pbo, fors[['Item Number',\"Sls Cd3\"]], on='Item Number', how='left')\n",
    "    pRItemBO['KEY3'] = pRItemBO['RBU'].astype(str)+\"_\"+pRItemBO['Sls Cd3'].astype(str)+\"_\"+pRItemBO['Item Number']\n",
    "    pRItemBO.drop(columns=['KEY','RBU','Item Number','Sls Cd3'], inplace=True)\n",
    "    \n",
    "    pRBUBO = pRItemBO.groupby(\"KEY3\")[pRItemBO.columns[-4:-1]].sum()\n",
    "    pRBUBO.reset_index(inplace=True)\n",
    "    col = pRItemBO.columns[-4:-1]\n",
    "    \n",
    "    warehouse_164z = pd.DataFrame()\n",
    "    warehouse_166z = pd.DataFrame()\n",
    "    warehouse_168z = pd.DataFrame()\n",
    "\n",
    "    # Filter rows for each warehouse and copy the \"Item Number\" column\n",
    "    warehouse_164z['KEY3'] = pRItemBO[pRItemBO['Warehouse'] == 164]['KEY3'].values\n",
    "    warehouse_166z['KEY3'] = pRItemBO[pRItemBO['Warehouse'] == 166]['KEY3'].values\n",
    "    warehouse_168z['KEY3'] = pRItemBO[pRItemBO['Warehouse'] == 168]['KEY3'].values\n",
    "\n",
    "    # Loop through the rows of the initial dataframe and populate the new dataframes\n",
    "    for month in col:\n",
    "        warehouse_164z[f\"164_{month}\"] = pRItemBO[pRItemBO['Warehouse'] == 164][month].values\n",
    "        warehouse_166z[f\"166_{month}\"] = pRItemBO[pRItemBO['Warehouse'] == 166][month].values\n",
    "        warehouse_168z[f\"168_{month}\"] = pRItemBO[pRItemBO['Warehouse'] == 168][month].values\n",
    "\n",
    "\n",
    "    warehouse_164z.reset_index(drop=True, inplace=True)\n",
    "    warehouse_166z.reset_index(drop=True, inplace=True)\n",
    "    warehouse_168z.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return pbo, pItemBO,warehouse_164y,warehouse_166y,warehouse_168y,pRBUBO,warehouse_164z,warehouse_166z,warehouse_168z\n",
    "\n",
    "pbo, pItemBO,warehouse_164y,warehouse_166y,warehouse_168y,pRBUBO,warehouse_164z,warehouse_166z,warehouse_168z = previousBO(con,fors)\n",
    "\n",
    "\n",
    "def sit_prep(con):\n",
    "    sit = pd.read_excel(\"UPDATE.xlsx\", sheet_name=\"SIT\")\n",
    "    sit = sit[[\"Item Number\",\"P/O Bus Unit\",\"ST Shipped Qty\"]]\n",
    "    sit['P/O Bus Unit'] = sit['P/O Bus Unit'].astype(int)\n",
    "    sit = sit[(sit[\"P/O Bus Unit\"]==164)|(sit[\"P/O Bus Unit\"]==166)|(sit[\"P/O Bus Unit\"]==168)]\n",
    "    sit = sit.pivot_table(index=\"Item Number\", columns=\"P/O Bus Unit\", values=\"ST Shipped Qty\",aggfunc=np.sum).rename_axis(index=None, columns=None)\n",
    "    sit = sit.fillna(0)\n",
    "    sit = sit.round(0)\n",
    "    sit.reset_index(inplace=True)\n",
    "    sit.rename(columns = {\"index\":\"Item Number\",164:\"ST_164\",166:\"ST_166\",168:\"ST_168\"}, inplace = True)\n",
    "    sit = pd.merge(sit, con[['Item Number','Conversion Factor']], on='Item Number',how='left')\n",
    "    sit['Conversion Factor'] = sit['Conversion Factor'].fillna(1)\n",
    "    sit.iloc[:,1:-1]=sit.iloc[:,1:-1].multiply(sit.iloc[:,-1], axis=0)\n",
    "    sit =  sit.drop(\"Conversion Factor\", axis=1)\n",
    "    return sit\n",
    "\n",
    "sit = sit_prep(con)\n",
    "\n",
    "\n",
    "def rbuMTD(mtd):\n",
    "    rbuMTD = mtd[['KEY3','Branch/\\nPlant','QtyShipped']]\n",
    "    rbuMTD = rbuMTD.rename(columns={\"Branch/\\nPlant\":\"Warehouse\"})\n",
    "    rbuMTD[\"Warehouse\"] = rbuMTD[\"Warehouse\"].astype(int)\n",
    "    rbuMTD[\"Warehouse\"] = rbuMTD[\"Warehouse\"].astype(str)\n",
    "    rbuMTD = rbuMTD[(rbuMTD['Warehouse']=='164')|(rbuMTD['Warehouse']=='166')|(rbuMTD['Warehouse']=='168')]\n",
    "    rbuMTD = rbuMTD.pivot_table(index=\"KEY3\", columns=\"Warehouse\", values=\"QtyShipped\",aggfunc=np.sum).rename_axis(index=None, columns=None)\n",
    "    rbuMTD = rbuMTD.fillna(0)\n",
    "    rbuMTD.reset_index(inplace=True)\n",
    "    rbuMTD.rename(columns = {\"index\":\"KEY3\",'164':\"Mtd_164\",'166':\"Mtd_166\",'168':\"Mtd_168\"}, inplace = True)\n",
    "    return rbuMTD\n",
    "\n",
    "rbuMTD = rbuMTD(mtd)\n",
    "\n",
    "def finalPrep(test,wo,orders,whsDF,sohb,sales,pfc,sit,warehouse_164,warehouse_166,warehouse_168,fors,rbuMTD,pItemBO,warehouse_164y,warehouse_166y,warehouse_168y):\n",
    "    \n",
    "    bo = orders[[\"Item Number\",\"TotalBackOrders\",\"Branch/\\nPlant\"]]\n",
    "    bo['WHS'] = bo['Branch/\\nPlant'].str.rsplit(' ',expand=True)[0]\n",
    "    bo = bo[(bo[\"WHS\"]==\"164\")|(bo[\"WHS\"]==\"166\")|(bo[\"WHS\"]==\"168\")]\n",
    "    bo = bo.pivot_table(index=\"Item Number\", columns=\"WHS\", values=\"TotalBackOrders\",aggfunc=np.sum).rename_axis(index=None, columns=None)\n",
    "    bo.reset_index(inplace=True)\n",
    "    bo = bo.rename(columns={\"index\":'Item Number'})\n",
    "    bo = bo.fillna(0)\n",
    "    bo = bo.rename(columns={\"164\":\"BO_164\",\"166\":\"BO_166\",\"168\":\"BO_168\"})\n",
    "    \n",
    "    final = test.groupby(['Item Number',\"SalesCode\"]).apply(lambda x: x.iloc[:, 4:17].sum())\n",
    "    final.reset_index(inplace=True)\n",
    "    final = pd.merge(final,sales, on='Item Number', how='outer')\n",
    "    final = pd.merge(final,warehouse_164, on='Item Number', how='outer')\n",
    "    final = pd.merge(final,warehouse_166, on='Item Number', how='outer')\n",
    "    final = pd.merge(final,warehouse_168, on='Item Number', how='outer')\n",
    "    \n",
    "    last = final.iloc[:,-25:]\n",
    "    \n",
    "    final = final.iloc[:, :-25]\n",
    "    final = pd.concat([final.iloc[:, :3], last, final.iloc[:, 3:]], axis=1)\n",
    "    \n",
    "    final = pd.merge(final, pfc, on='Item Number', how='outer')\n",
    "    \n",
    "    last = final.iloc[:,-3:]\n",
    "    final = final.iloc[:, :-3]\n",
    "    final = pd.concat([final.iloc[:, :28], last, final.iloc[:, 28:]], axis=1)\n",
    "    \n",
    "    \n",
    "    final = pd.merge(final,bo,on='Item Number',how='outer')\n",
    "    final = pd.merge(final,whsDF, on='Item Number', how='outer')\n",
    "    final = pd.merge(final,sit, on='Item Number', how='outer')\n",
    "    final = pd.merge(final,sohb, on='Item Number', how='left')\n",
    "    final = pd.merge(final,wo,on='Item Number', how='outer')\n",
    "    \n",
    "    fors = fors[[\"Item Number\",'Plan Fmly',\"Sls Cd4\",\"ABC 1 Sls\", 'Safety Stk 164', 'Safety Stk 166','Safety Stk 168']]\n",
    "    fors = fors.rename(columns={\"Safety Stk 164\":\"SS_164\",\"Safety Stk 166\":\"SS_166\",\"Safety Stk 168\":\"SS_168\"})\n",
    "    \n",
    "    rbuMTD[['RBU', 'SalesCode','Item Number']] = rbuMTD['KEY3'].str.split(pat='_', n=2, expand=True)\n",
    "    rbuMTD = rbuMTD.groupby('Item Number')[['Mtd_164', 'Mtd_166', 'Mtd_168']].sum().reset_index()\n",
    "    rbuMTD['Item Number'] = rbuMTD['Item Number'].astype(str)\n",
    "    final = pd.merge(final,rbuMTD, on='Item Number', how='left')\n",
    "    \n",
    "    final = pd.merge(final,pItemBO, on='Item Number', how='left')\n",
    "    final = pd.merge(final,warehouse_164y, on='Item Number', how='left')\n",
    "    final = pd.merge(final,warehouse_166y, on='Item Number', how='left')\n",
    "    final = pd.merge(final,warehouse_168y, on='Item Number', how='left')\n",
    "\n",
    "    \n",
    "    final = pd.merge(final,fors, on='Item Number', how='left')\n",
    "    final = final.fillna(0)\n",
    "    return final\n",
    "\n",
    "final = finalPrep(test,wo,orders,whsDF,sohb,sales,pfc,sit,warehouse_164,warehouse_166,warehouse_168,fors,rbuMTD,pItemBO,warehouse_164y,warehouse_166y,warehouse_168y)\n",
    "\n",
    "\n",
    "\n",
    "def rbuWarehouse(allsales,fors):\n",
    "    allsales = pd.merge(allsales,fors[['Item Number',\"Sls Cd3\"]], on='Item Number',how='left')\n",
    "    allsales['Sls Cd3'] = allsales['Sls Cd3'].replace(' ', np.nan)\n",
    "    allsales['Sls Cd3'] = allsales['Sls Cd3'].astype(float).astype(pd.Int64Dtype())\n",
    "    allsales['KEY3'] = allsales['RBU'].astype(str)+\"_\"+allsales['Sls Cd3'].astype(str)+\"_\"+allsales['Item Number'].astype(str)\n",
    "    \n",
    "    rbuSALES = allsales\n",
    "    rbuSALES = rbuSALES.rename(columns={\"Sls Cd3\":\"SalesCode\"})\n",
    "    rbuSALESx = rbuSALES.drop(columns=['RBU','Item Number','SalesCode'])\n",
    "    last_column = rbuSALESx.columns[-1]\n",
    "    rbuSALESx = rbuSALESx[[last_column] + [col for col in rbuSALESx.columns if col != last_column]]\n",
    "    \n",
    "    \n",
    "    col = list(rbuSALESx.columns[-6:])\n",
    "\n",
    "    warehouse_164x = pd.DataFrame()\n",
    "    warehouse_166x = pd.DataFrame()\n",
    "    warehouse_168x = pd.DataFrame()\n",
    "\n",
    "    # Filter rows for each warehouse and copy the \"Item Number\" column\n",
    "    warehouse_164x['KEY3'] = rbuSALESx[rbuSALESx['Warehouse'] == 164]['KEY3'].values\n",
    "    warehouse_166x['KEY3'] = rbuSALESx[rbuSALESx['Warehouse'] == 166]['KEY3'].values\n",
    "    warehouse_168x['KEY3'] = rbuSALESx[rbuSALESx['Warehouse'] == 168]['KEY3'].values\n",
    "\n",
    "    # Loop through the rows of the initial dataframe and populate the new dataframes\n",
    "    for month in col:\n",
    "        warehouse_164x[f\"164_{month}\"] = rbuSALESx[rbuSALESx['Warehouse'] == 164][month].values\n",
    "        warehouse_166x[f\"166_{month}\"] = rbuSALESx[rbuSALESx['Warehouse'] == 166][month].values\n",
    "        warehouse_168x[f\"168_{month}\"] = rbuSALESx[rbuSALESx['Warehouse'] == 168][month].values\n",
    "\n",
    "\n",
    "    warehouse_164x.reset_index(drop=True, inplace=True)\n",
    "    warehouse_166x.reset_index(drop=True, inplace=True)\n",
    "    warehouse_168x.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    return rbuSALES,warehouse_164x,warehouse_166x,warehouse_168x\n",
    "\n",
    "rbuSALES,warehouse_164x,warehouse_166x,warehouse_168x = rbuWarehouse(allsales,fors)\n",
    "\n",
    "\n",
    "def rbuORDERS(orders):\n",
    "    rbuORDERS = orders[['BU\\nHeader',\"Sales Reporting Code 03\",\"Item Number\",'Branch/\\nPlant',\n",
    "                        'TotalOpenOrders',\"TotalBackOrders\",\"PastDue_BO\",'CurrDue_BO']]\n",
    "    rbuORDERS[['Warehouse', 'PLANTNAME']] = rbuORDERS['Branch/\\nPlant'].str.split(pat='-', n=1, expand=True)\n",
    "    rbuORDERS['Warehouse'] = rbuORDERS['Warehouse'].str.strip()\n",
    "    rbuORDERS['Warehouse'] = rbuORDERS['Warehouse'].astype(int)\n",
    "    rbuORDERS['Warehouse'] = rbuORDERS['Warehouse'].astype(str)\n",
    "    rbuORDERS = rbuORDERS.rename(columns={\"BU\\nHeader\":\"RBU\",\"Sales Reporting Code 03\":\"SalesCode\"})\n",
    "    rbuORDERS.drop(columns=['PLANTNAME','Branch/\\nPlant'],inplace=True)\n",
    "    rbuORDERS['RBU'] = rbuORDERS['RBU'].astype(int)\n",
    "    rbuORDERS['SalesCode'] = rbuORDERS['SalesCode'].astype(int)\n",
    "    rbuORDERS['Item Number'] = rbuORDERS['Item Number'].astype(str)\n",
    "    rbuORDERS['KEY3'] = rbuORDERS['RBU'].astype(str)+\"_\"+rbuORDERS['SalesCode'].astype(str)+\"_\"+rbuORDERS['Item Number'].astype(str)\n",
    "    last_column = rbuORDERS.columns[-1]\n",
    "    rbuORDERS = rbuORDERS[[last_column] + [col for col in rbuORDERS.columns if col != last_column]]\n",
    "    \n",
    "    wOrders = rbuORDERS[['KEY3','TotalOpenOrders','Warehouse']].pivot_table(index=\"KEY3\", columns=\"Warehouse\", values=\"TotalOpenOrders\",aggfunc=np.sum).rename_axis(index=None, columns=None)\n",
    "    wCurrBO = rbuORDERS[['KEY3','CurrDue_BO','Warehouse']].pivot_table(index=\"KEY3\", columns=\"Warehouse\", values=\"CurrDue_BO\",aggfunc=np.sum).rename_axis(index=None, columns=None)\n",
    "    wPastBO = rbuORDERS[['KEY3','PastDue_BO','Warehouse']].pivot_table(index=\"KEY3\", columns=\"Warehouse\", values=\"PastDue_BO\",aggfunc=np.sum).rename_axis(index=None, columns=None)\n",
    "    \n",
    "    wOrders = wOrders.fillna(0)\n",
    "    wCurrBO = wCurrBO.fillna(0)\n",
    "    wPastBO = wPastBO.fillna(0)\n",
    "\n",
    "    wOrders.reset_index(inplace=True)\n",
    "    wCurrBO.reset_index(inplace=True)\n",
    "    wPastBO.reset_index(inplace=True)\n",
    "\n",
    "    wOrders.rename(columns = {\"index\":\"KEY3\",'164':\"OpenOrders_164\",'166':\"OpenOrders_166\",'168':\"OpenOrders_168\"}, inplace = True)\n",
    "    wCurrBO.rename(columns = {\"index\":\"KEY3\",'164':\"CurrBO_164\",'166':\"CurrBO_166\",'168':\"CurrBO_168\"}, inplace = True)\n",
    "    wPastBO.rename(columns = {\"index\":\"KEY3\",'164':\"PastBO_164\",'166':\"PastBO_166\",'168':\"PastBO_168\"}, inplace = True)\n",
    "    \n",
    "    return wOrders,wCurrBO,wPastBO\n",
    "    \n",
    "wOrders,wCurrBO,wPastBO = rbuORDERS(orders)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rbuSummary(test,ofc,rbuSALES,warehouse_164x,warehouse_166x,warehouse_168x,lfc,acc,wOrders,wCurrBO,wPastBO,rbuMTD,pRBUBO,warehouse_164z,warehouse_166z,warehouse_168z):\n",
    "    \n",
    "    rbuSALESy = rbuSALES.groupby(['KEY3',\"RBU\",'Item Number','SalesCode']).apply(lambda x: x.iloc[:, 3:9].sum())\n",
    "    rbuSALESy.reset_index(inplace=True)\n",
    "    \n",
    "    test = pd.merge(test, rbuSALESy, on='KEY3', how='outer',suffixes=('', '_y'))\n",
    "    test['Item Number'].fillna(test['Item Number_y'], inplace=True)\n",
    "    test['SalesCode'].fillna(test['SalesCode_y'], inplace=True)\n",
    "    test['RBU'].fillna(test['RBU_y'], inplace=True)\n",
    "    test.drop(test.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    test['RBU']= test['RBU'].astype(int)\n",
    "    \n",
    "    test = pd.merge(test, lfc, on='KEY3', how='outer',suffixes=('', '_y'))\n",
    "    test['Item Number'].fillna(test['Item Number_y'], inplace=True)\n",
    "    test['SalesCode'].fillna(test['SalesCode_y'], inplace=True)\n",
    "    test['RBU'].fillna(test['RBU_y'], inplace=True)\n",
    "    test.drop(test.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    test['RBU']= test['RBU'].astype(int)\n",
    "    \n",
    "    last = test.iloc[:,-3:]\n",
    "    test = test.iloc[:, :-3]\n",
    "    test = pd.concat([test.iloc[:, :5], last, test.iloc[:, 5:]], axis=1)\n",
    "    \n",
    "    test = pd.merge(test,warehouse_164x, on='KEY3', how='left')\n",
    "    test = pd.merge(test,warehouse_166x, on='KEY3', how='left')\n",
    "    test = pd.merge(test,warehouse_168x, on='KEY3', how='left')\n",
    "    \n",
    "    test = pd.merge(test,rbuMTD, on='KEY3', how='left',suffixes=('', '_y'))\n",
    "    test['Item Number'].fillna(test['Item Number_y'], inplace=True)\n",
    "    test['SalesCode'].fillna(test['SalesCode_y'], inplace=True)\n",
    "    test['RBU'].fillna(test['RBU_y'], inplace=True)\n",
    "    test.drop(test.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    test['RBU']= test['RBU'].astype(int)\n",
    "    \n",
    "    test = pd.merge(test,wOrders, on='KEY3', how='left')\n",
    "    test = pd.merge(test,wCurrBO, on='KEY3', how='left')\n",
    "    test = pd.merge(test,wPastBO, on='KEY3', how='left')\n",
    "    \n",
    "    \n",
    "    rbu = acc[['GROUP','DIVISION','RBU','SalesCode']]\n",
    "    rbu = rbu.drop_duplicates(subset=['GROUP','DIVISION','RBU','SalesCode'], keep='last')\n",
    "    rbu['SalesCode'] = rbu['SalesCode'].replace(' ', np.nan)\n",
    "    rbu['SalesCode'] = rbu['SalesCode'].astype(float).astype(pd.Int64Dtype())\n",
    "    rbu['RBU'] = rbu['RBU'].replace(' ', np.nan)\n",
    "    rbu['RBU'] = rbu['RBU'].astype(float).astype(pd.Int64Dtype())\n",
    "    \n",
    "    \n",
    "    \n",
    "    rbu['KEY4'] = rbu['RBU'].astype(str)+\"_\"+rbu['SalesCode'].astype(str)\n",
    "\n",
    "\n",
    "    #test['RBU'] = test['RBU'].replace(' ', np.nan)\n",
    "    #test['RBU'] = test['RBU'].astype(float).astype(pd.Int64Dtype())\n",
    "    test['KEY4'] = test['RBU'].astype(str)+\"_\"+test['SalesCode'].astype(str)\n",
    "\n",
    "    test.drop(columns=['GROUP','DIVISION'], inplace=True)\n",
    "\n",
    "    test = pd.merge(test,rbu[['KEY4','GROUP','DIVISION']], on='KEY4',how='left')\n",
    "    \n",
    "    test = pd.merge(test,pRBUBO, on='KEY3', how='left')\n",
    "    test = pd.merge(test,warehouse_164z, on='KEY3', how='left')\n",
    "    test = pd.merge(test,warehouse_166z, on='KEY3', how='left')\n",
    "    test = pd.merge(test,warehouse_168z, on='KEY3', how='left')\n",
    "    \n",
    "    test = test.drop_duplicates(subset='KEY3', keep='last')\n",
    "    \n",
    "    test = test.fillna(0)\n",
    "    \n",
    "    return test\n",
    "\n",
    "test = rbuSummary(test,ofc,rbuSALES,warehouse_164x,warehouse_166x,warehouse_168x,lfc,acc,wOrders,wCurrBO,wPastBO,rbuMTD,pRBUBO,warehouse_164z,warehouse_166z,warehouse_168z)\n",
    "\n",
    "cols = ['QA_164','QA_166','QA_168',\"Rec_164\",\"Rec_168\",\"Rec_166\",\"ST_164\",\"ST_166\",\"ST_168\"]\n",
    "\n",
    "for i in cols:\n",
    "    if i in list(final.columns):\n",
    "        pass\n",
    "    else:\n",
    "        final[i] = 0\n",
    "        \n",
    "def indicator(fc,final):\n",
    "    ind = pd.read_excel(\"FILE.xlsx\",sheet_name=\"INDICATOR\")\n",
    "    ind['SignalC'] = ind['SignalC'].astype(str)\n",
    "    final['Plan Fmly'] = final['Plan Fmly'].astype(str)\n",
    "    ind['ColC'] = list(fc.columns)[2]\n",
    "    ind = ind[ind['GROUP']==\"A1\"]\n",
    "    dfs = []\n",
    "    dfs = pd.DataFrame(dfs)\n",
    "    dfs['Item Number'] = final['Item Number'].astype(str)\n",
    "    def A(row):\n",
    "        A = ind[ind['CAT']==\"A\"]\n",
    "\n",
    "        colC_value = list(A['ColC'])[0]\n",
    "\n",
    "        plan_fmly = row['Plan Fmly']\n",
    "\n",
    "        bo = row['TotalBackOrders']\n",
    "\n",
    "        if plan_fmly == \"DIS\" and bo > 0:\n",
    "            return list(A[A['SignalC']==\"FC = 0\"]['Status'])[0]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def B(row):\n",
    "        B = ind[ind['CAT']==\"B\"]\n",
    "\n",
    "        colC_value = list(B['ColC'])[0]\n",
    "\n",
    "        plan_fmly = row['Plan Fmly']\n",
    "\n",
    "        bo = row['TotalBackOrders']\n",
    "\n",
    "        if row[colC_value] == 0 and plan_fmly == \"980\" and bo > 0:\n",
    "            return list(B[B['SignalC']==\"FC = 0\"]['Status'])[0]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def C(row):\n",
    "        C = ind[ind['CAT']==\"C\"]\n",
    "\n",
    "        colC_value = list(C['ColC'])[0]\n",
    "\n",
    "        bypass = row['WO ByPass']\n",
    "\n",
    "        bo = row['TotalBackOrders']\n",
    "\n",
    "        if bypass > 0 and bo > 0:\n",
    "            return list(C[C['SignalC']==\"FC / D\"]['Status'])[0]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def D(row):\n",
    "        D = ind[ind['CAT']==\"D\"]\n",
    "\n",
    "        colC_value = list(D['ColC'])[0]\n",
    "\n",
    "        bypass = row['WO ByPass']\n",
    "\n",
    "        bo = row['TotalBackOrders']\n",
    "\n",
    "        if row[colC_value] == 0 and bypass == 0 and bo > 0:\n",
    "            return list(D[D['SignalC']==\"FC = 0\"]['Status'])[0]\n",
    "        elif row[colC_value] > (row['TotalOpenOrders']+row['QtyShipped']) and bypass == 0 and bo > 0:\n",
    "            return list(D[D['SignalC']==\"FC > D\"]['Status'])[0]\n",
    "        elif row[colC_value] < (row['TotalOpenOrders']+row['QtyShipped']) and bypass == 0 and bo > 0:\n",
    "            return list(D[D['SignalC']==\"FC < D\"]['Status'])[0]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    dfs['A'] = final.apply(A, axis=1)\n",
    "    dfs['B'] = final.apply(B, axis=1)\n",
    "    dfs['C'] = final.apply(C, axis=1)\n",
    "    dfs['D'] = final.apply(D, axis=1)\n",
    "    \n",
    "    def Issue(row):\n",
    "        if row['A'] == 0:\n",
    "            if row['B'] == 0:\n",
    "                if row['C'] == 0:\n",
    "                    if row['D'] == 0:\n",
    "                        return 0\n",
    "                    else:\n",
    "                        return row['D']\n",
    "                else:\n",
    "                    return row['C']\n",
    "            else:\n",
    "                return row['B']\n",
    "        else:\n",
    "            return row['A']\n",
    "                   \n",
    "    dfs['BO_CommentA'] = dfs.apply(Issue, axis=1)\n",
    "    \n",
    "    final = pd.merge(final,dfs[['Item Number','BO_CommentA']], on='Item Number', how='left')\n",
    "                           \n",
    "    \n",
    "    return final\n",
    "\n",
    "final = indicator(fc,final)\n",
    "\n",
    "\n",
    "def indicator2(final):\n",
    "    ind = pd.read_excel(\"FILE.xlsx\",sheet_name=\"INDICATOR\")\n",
    "    ind['SignalC'] = ind['SignalC'].astype(str)\n",
    "    #final['Plan Fmly'] = final['Plan Fmly'].astype(str)\n",
    "    ind['ColC'] = list(fc.columns)[2]\n",
    "    ind = ind[ind['GROUP']==\"B1\"]\n",
    "    final['3 >= ZeroSales'] = (final.iloc[:,3:9].astype(int) == 0).sum(axis=1) >= 3\n",
    "    final['std'] = np.std(final.iloc[:,3:9],axis=1)\n",
    "    dfs = []\n",
    "    dfs = pd.DataFrame(dfs)\n",
    "    dfs['Item Number'] = final['Item Number'].astype(str)\n",
    "    def A(row):\n",
    "        A = ind[ind['CAT']==\"A\"]\n",
    "\n",
    "        colC_value = list(A['ColC'])[0]\n",
    "\n",
    "\n",
    "        commentA = row['BO_CommentA']\n",
    "        pareto = row['ABC 1 Sls']\n",
    "\n",
    "        std = row['std']\n",
    "\n",
    "        avg = row['6mAvg']\n",
    "\n",
    "        mtd = row['QtyShipped']+row['TotalOpenOrders']\n",
    "\n",
    "        zeroSales = row['3 >= ZeroSales']\n",
    "\n",
    "        if commentA != \"0\" and pareto == 'D' and (std+avg) < mtd:\n",
    "            return list(A[A['SignalC']==\"6mA+std > mtd\"]['Status'])[0]\n",
    "        if commentA != \"0\" and pareto == 'D' and zeroSales == True:\n",
    "            return list(A[A['SignalC']==\"3 >= ZeroSales\"]['Status'])[0]\n",
    "        else:\n",
    "            return commentA\n",
    "    \n",
    "    dfs['BO_CommentA'] = final.apply(A, axis=1)\n",
    "    \n",
    "    final = final.drop('BO_CommentA',axis=1)\n",
    "    \n",
    "    final = pd.merge(final,dfs[['Item Number','BO_CommentA']], on='Item Number', how='left')\n",
    "    \n",
    "    \n",
    "    dfs = []\n",
    "    dfs = pd.DataFrame(dfs)\n",
    "    dfs['Item Number'] = final['Item Number'].astype(str)\n",
    "    \n",
    "    def B(row):\n",
    "        B = ind[ind['CAT']==\"B\"]\n",
    "\n",
    "        colC_value = list(B['ColC'])[0]\n",
    "\n",
    "\n",
    "        commentA = row['BO_CommentA']\n",
    "        pareto = row['ABC 1 Sls']\n",
    "\n",
    "        std = row['std']\n",
    "\n",
    "        avg = row['6mAvg']\n",
    "\n",
    "        mtd = row['QtyShipped']+row['TotalOpenOrders']\n",
    "\n",
    "        zeroSales = row['3 >= ZeroSales']\n",
    "\n",
    "        if commentA == \"Demand Exceed Forecast\" and pareto != 'D' and (std+avg) < mtd:\n",
    "            return list(B[B['SignalC']==\"6mA+std > mtd\"]['Status'])[0]\n",
    "        if commentA == \"Demand Exceed Forecast\" and pareto != 'D' and zeroSales == True:\n",
    "            return list(B[B['SignalC']==\"3 >= ZeroSales\"]['Status'])[0]\n",
    "        else:\n",
    "            return commentA\n",
    "    \n",
    "    dfs['BO_CommentA'] = final.apply(B, axis=1)\n",
    "\n",
    "    final = final.drop('BO_CommentA',axis=1)\n",
    "    \n",
    "    final = pd.merge(final,dfs[['Item Number','BO_CommentA']], on='Item Number', how='left')\n",
    "    \n",
    "    final = final.drop_duplicates(subset='Item Number', keep='first')\n",
    "    \n",
    "    return final\n",
    "    \n",
    "final = indicator2(final)\n",
    "\n",
    "def publishExcelFile(acc,UnRegistered, UnRegisteredOrders,test,final):\n",
    "    excel_file = 'DashFile.xlsx'\n",
    "    book = load_workbook(excel_file)\n",
    "\n",
    "\n",
    "    with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a',if_sheet_exists='replace') as writer:\n",
    "        writer.book = book\n",
    "\n",
    "\n",
    "        if 'CustomerSales' in writer.book.sheetnames:\n",
    "            sheet = writer.book['CustomerSales']\n",
    "            sheet.delete_rows(sheet.min_row + 1, sheet.max_row)\n",
    "\n",
    "\n",
    "        acc.to_excel(writer, sheet_name='CustomerSales', index=False)\n",
    "        \n",
    "\n",
    "        if 'UnregisteredSales' in writer.book.sheetnames:\n",
    "            sheet = writer.book['UnregisteredSales']\n",
    "            sheet.delete_rows(sheet.min_row + 1, sheet.max_row)\n",
    "\n",
    "        UnRegistered.to_excel(writer, sheet_name='UnregisteredSales', index=False)\n",
    "\n",
    "\n",
    "        if 'UnregisteredOrders' in writer.book.sheetnames:\n",
    "            sheet = writer.book['UnregisteredOrders']\n",
    "            sheet.delete_rows(sheet.min_row + 1, sheet.max_row)\n",
    "\n",
    "        UnRegisteredOrders.to_excel(writer, sheet_name='UnregisteredOrders', index=False)\n",
    "\n",
    "        if 'RBUSummary' in writer.book.sheetnames:\n",
    "            sheet = writer.book['RBUSummary']\n",
    "            sheet.delete_rows(sheet.min_row + 1, sheet.max_row)\n",
    "\n",
    "        test.to_excel(writer, sheet_name='RBUSummary', index=False)\n",
    "\n",
    "        if 'ItemNumbers' in writer.book.sheetnames:\n",
    "            sheet = writer.book['ItemNumbers']\n",
    "            sheet.delete_rows(sheet.min_row + 1, sheet.max_row)\n",
    "\n",
    "        final.to_excel(writer, sheet_name='ItemNumbers', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    book.save(excel_file)\n",
    "    \n",
    "\n",
    "publishExcelFile(acc,UnRegistered, UnRegisteredOrders,test,final)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d3d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
